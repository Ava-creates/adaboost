{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ava-creates/adaboost/blob/main/adaboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqDS8GfJmsss",
        "outputId": "0900aa21-182b-4f63-f9d2-a80f9fa4c33a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
            " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
            " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
            " ...\n",
            " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
            " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
            " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import numpy as np\n",
        "data = load_breast_cancer()\n",
        "\n",
        "X=data[\"data\"]\n",
        "y=data[\"target\"]\n",
        "y.reshape((X.shape[0],1))\n",
        "\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7fjmQ14nAxa",
        "outputId": "ad5d194d-c1d2-49bf-949c-f73ef548fc39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(569, 30)\n",
            "(569,)\n",
            "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
            " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
            " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
            " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
            " 'smoothness error' 'compactness error' 'concavity error'\n",
            " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
            " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
            " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
            " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(data.feature_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxiL68XHnNJb"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ouPAV0HtnBYT"
      },
      "outputs": [],
      "source": [
        "from sklearn import preprocessing\n",
        "scaler_train = preprocessing.StandardScaler().fit(X_train)\n",
        "scaler_test = preprocessing.StandardScaler().fit(X_test)\n",
        "scale=preprocessing.StandardScaler().fit(X)\n",
        "X_train_scaled = scaler_train.transform(X_train)\n",
        "X_test_scaled= scaler_test.transform(X_test)\n",
        "X_scaled=scale.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Baum9HkVmXB5"
      },
      "outputs": [],
      "source": [
        "class Classifier:\n",
        "  \n",
        "  def __init__(self):\n",
        "    self.threshold=0\n",
        "    self.sign= 1\n",
        "    self.feature= 0\n",
        "    self.alpha = 0\n",
        "\n",
        "  def prediction(self, X):\n",
        "    y_predict= np.ones(X.shape[0])\n",
        "    X_j= X[:, self.feature]\n",
        "    \n",
        "\n",
        "    if(self.sign ==1):\n",
        "      y_predict[X_j<self.threshold]=-1\n",
        "\n",
        "    else:\n",
        "\n",
        "      y_predict[X_j<self.threshold]=1\n",
        "\n",
        "    return y_predict\n",
        "\n",
        "  def cal_alpha(self, min_error):\n",
        "     \n",
        "    self.alpha = 0.5 * np.log((1.0 - min_error) / (min_error))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSRRMYGShDpD"
      },
      "outputs": [],
      "source": [
        "class ensembeled_adaboost:\n",
        "  def __init__ (self, no_classifiers):\n",
        "    self.no_classifiers=no_classifiers\n",
        "    self.classifier_list= []\n",
        "\n",
        "  def find( self, classifiers, X, y, w):\n",
        "    a=classifiers\n",
        "    \n",
        "    features=X.shape[1]\n",
        "    min_error=1\n",
        "    feature=0\n",
        "    \n",
        "    for i in range(0, features):\n",
        "      X_j = X[:, i]\n",
        "      t = np.unique(X_j)\n",
        "      row= X.shape[0]\n",
        "      for t_ in t:\n",
        "        \n",
        "        y_estimate = np.ones(X.shape[0])\n",
        "        sign=1\n",
        "        \n",
        "        y_estimate[X_j < t_]= -1\n",
        "\n",
        "        error= sum(w[y_estimate!=y])/row\n",
        "\n",
        "        if(error>.5):\n",
        "          sign=-1\n",
        "          error=1-error\n",
        "\n",
        "        if(error<min_error):\n",
        "          min_error= error\n",
        "          a.feature=i\n",
        "          a.sign=sign\n",
        "          a.threshold= t_\n",
        "\n",
        "      a.cal_alpha(min_error)\n",
        "\n",
        "      \n",
        "\n",
        "  def ensemble(self, X, y):\n",
        "      row= X.shape[0]\n",
        "      w = np.full(row, (1 / row))\n",
        "      for i in range(0, self.no_classifiers):\n",
        "\n",
        "        classifiers  = Classifier()\n",
        "\n",
        "        self.find(classifiers, X, y, w)\n",
        "\n",
        "        y_predict = classifiers.prediction(X)\n",
        "\n",
        "        w = w*np.exp(-classifiers.alpha * y * y_predict)/ np.sum(w)\n",
        "         \n",
        "        self.classifier_list.append(classifiers)\n",
        "\n",
        "  def predict(self, X):\n",
        "        \n",
        "        a= np.zeros(X.shape[0])\n",
        "\n",
        "        a=a.reshape(X.shape[0],1)\n",
        "\n",
        "\n",
        "        for classifier in self.classifier_list:\n",
        "          #print((classifier.alpha * classifier.prediction(X)).shape)\n",
        "          #print(a.shape)\n",
        "          a = a+ classifier.alpha * (classifier.prediction(X).reshape(X.shape[0], 1))\n",
        "\n",
        "        y_pred = a\n",
        "        y_pred = np.sign(y_pred)\n",
        "\n",
        "        return y_pred\n",
        "\n",
        "\n",
        "       \n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GngtXJMsiXtT",
        "outputId": "66f69f49-4d5e-4585-97a4-35ff80655e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.6382978723404256\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "c = ensembeled_adaboost(10)\n",
        "c.ensemble(X_train, y_train)\n",
        "y_predicted=c.predict(X_test)\n",
        "\n",
        "print(\"Test Accuracy: {}\".format(accuracy_score(y_test, y_predicted)))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0LMhCnv28x-",
        "outputId": "2c9c54c3-a991-47e2-9f69-af779f87b3df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4601, 58)\n",
            "[1. 1. 1. ... 0. 0. 0.]\n",
            "[[0.000e+00 6.400e-01 6.400e-01 ... 3.756e+00 6.100e+01 2.780e+02]\n",
            " [2.100e-01 2.800e-01 5.000e-01 ... 5.114e+00 1.010e+02 1.028e+03]\n",
            " [6.000e-02 0.000e+00 7.100e-01 ... 9.821e+00 4.850e+02 2.259e+03]\n",
            " ...\n",
            " [3.000e-01 0.000e+00 3.000e-01 ... 1.404e+00 6.000e+00 1.180e+02]\n",
            " [9.600e-01 0.000e+00 0.000e+00 ... 1.147e+00 5.000e+00 7.800e+01]\n",
            " [0.000e+00 0.000e+00 6.500e-01 ... 1.250e+00 5.000e+00 4.000e+01]]\n"
          ]
        }
      ],
      "source": [
        "from numpy import genfromtxt\n",
        "\n",
        "my_data = genfromtxt('/content/drive/MyDrive/Colab Notebooks/spambase.csv', delimiter=',')\n",
        "print(my_data.shape)\n",
        "\n",
        "\n",
        "\n",
        "label=my_data[:, -1]\n",
        "data= my_data[: , :-1]\n",
        "print(label)\n",
        "print(data)\n",
        "label= np.where(label ==0, -1, 1)\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, label, test_size=0.33, random_state=42)\n",
        "\n",
        "from sklearn import preprocessing\n",
        "scaler_train = preprocessing.StandardScaler().fit(X_train)\n",
        "scaler_test = preprocessing.StandardScaler().fit(X_test)\n",
        "scale=preprocessing.StandardScaler().fit(X)\n",
        "X_train_scaled = scaler_train.transform(X_train)\n",
        "X_test_scaled= scaler_test.transform(X_test)\n",
        "X_scaled=scale.transform(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hyz7PyK41du",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d03b0de-3150-46b3-d4e9-cd94c128f424"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 79.78933508887425\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "c = ensembeled_adaboost(50)\n",
        "c.ensemble(X_train, y_train)\n",
        "y_predicted=c.predict(X_test)\n",
        "\n",
        "print(\"Test Accuracy: {}\".format(accuracy_score(y_test, y_predicted)*100))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "adaboost.ipynb",
      "provenance": [],
      "mount_file_id": "1y931fyGLrDXhcRM1GulRGk2Vh_XWDvqO",
      "authorship_tag": "ABX9TyPX+rZSqMzLQwJbIB9gl4ca",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}